{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = pd.read_csv(\"seer_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_encoded.reset_index(drop=True)\n",
    "N = dataset.shape[0]\n",
    "\n",
    "time_column = \"time\"\n",
    "event_column = \"cod\"\n",
    "features = np.setdiff1d(dataset.columns, [time_column, event_column] ).tolist()\n",
    "\n",
    "# Building training and testing sets\n",
    "index_train, index_test = train_test_split( range(N), test_size = 0.1, random_state = 142857, stratify = dataset[event_column])\n",
    "data_train = dataset.loc[index_train].reset_index( drop = True )\n",
    "data_test  = dataset.loc[index_test].reset_index( drop = True )\n",
    "N2 = data_train.shape[0]\n",
    "\n",
    "index_train, index_val = train_test_split( range(N2), test_size = 0.1, random_state = 142857, stratify = data_train[event_column])\n",
    "data_train = dataset.loc[index_train].reset_index( drop = True )\n",
    "data_val  = dataset.loc[index_val].reset_index( drop = True )\n",
    "\n",
    "# Creating the X, T and E inputs\n",
    "X_train, X_test, X_val = data_train[features], data_test[features], data_val[features]\n",
    "time_train, time_test, time_val = data_train[time_column], data_test[time_column], data_val[time_column]\n",
    "event_train, event_test, event_val = data_train[event_column], data_test[event_column], data_val[event_column]\n",
    "\n",
    "step = 5\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSF\n",
    "# Expected CPU runtime: <10s\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "bool_indicator_train =  [bool(x) for x in event_train]\n",
    "y_train_tuple =  c = np.array(list(zip(bool_indicator_train, time_train)), dtype=[(\"a\", bool), (\"b\", float)])\n",
    "rsf = RandomSurvivalForest(n_estimators=100, min_samples_split=6, \n",
    "                            min_samples_leaf=3, n_jobs=16)\n",
    "rsf.fit(X_train, y_train_tuple)\n",
    "rsf_func = rsf.predict_survival_function(X_test)\n",
    "# survprob_rsf= np.array(1-rsf.predict_survival_function(X_test, times = np.arange(time_test.min(),time_test.max(),step)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxPH\n",
    "# Expected CPU runtime: <10s\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "bool_indicator_train =  [bool(x) for x in event_train]\n",
    "y_train_tuple =  c = np.array(list(zip(bool_indicator_train, time_train)), dtype=[(\"a\", bool), (\"b\", float)])\n",
    "CoxPH = CoxPHSurvivalAnalysis(alpha=0.1,verbose=0) # alpha=0 causes singular matrix error\n",
    "\n",
    "CoxPH.fit(X_train, y_train_tuple)\n",
    "coxph_func = CoxPH.predict_survival_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSurv\n",
    "# Expected CPU runtime: <30s\n",
    "from pycox.models import CoxPH\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "# set default tensor type\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "y_train_tuple = (time_train.to_numpy().astype(np.float32), event_train.to_numpy().astype(np.float32))\n",
    "y_val_tuple = (time_val.to_numpy().astype(np.float32), event_val.to_numpy().astype(np.float32))\n",
    "val = X_val.to_numpy().astype(np.float32), y_val_tuple\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout, output_bias=output_bias)\n",
    "deepsurv = CoxPH(net, tt.optim.Adam, device=device)\n",
    "deepsurv.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = deepsurv.fit(X_train.to_numpy().astype(np.float32), y_train_tuple, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)\n",
    "_ = deepsurv.compute_baseline_hazards()\n",
    "deepsurv_pred = deepsurv.predict_surv_df(X_test.to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxCC\n",
    "# Expected CPU runtime: <30s\n",
    "from pycox.models import CoxCC\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "batch_size = 4096\n",
    "epochs = 10000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "y_train_tuple = (time_train.to_numpy().astype(np.float32), event_train.to_numpy().astype(np.float32))\n",
    "y_val_tuple = (time_val.to_numpy().astype(np.float32), event_val.to_numpy().astype(np.float32))\n",
    "val = X_val.to_numpy().astype(np.float32), y_val_tuple\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "output_bias = False\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout, output_bias=output_bias)\n",
    "coxcc = CoxCC(net, tt.optim.Adam, device=device)\n",
    "coxcc.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = coxcc.fit(X_train.to_numpy().astype(np.float32), y_train_tuple, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)\n",
    "_ = coxcc.compute_baseline_hazards()\n",
    "coxcc_pred = coxcc.predict_surv_df(X_test.to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepHit\n",
    "# Expected CPU runtime: 11m19s\n",
    "from pycox.models import DeepHitSingle\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "\n",
    "num_durations = 250\n",
    "batch_size = 4096*4\n",
    "epochs = 10000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "y_train_tuple = labtrans.fit_transform(time_train.to_numpy().astype(np.float32), event_train.to_numpy().astype(np.float32))\n",
    "y_val_tuple = labtrans.fit_transform(time_val.to_numpy().astype(np.float32), event_val.to_numpy().astype(np.float32))\n",
    "val = X_val.to_numpy().astype(np.float32), y_val_tuple\n",
    "\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = num_durations\n",
    "batch_norm = True\n",
    "dropout = 0.0\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "deephit = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts, device=device)\n",
    "deephit.optimizer.set_lr(0.001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=100)]\n",
    "verbose = False\n",
    "log = deephit.fit(X_train.to_numpy().astype(np.float32), y_train_tuple, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
    "deephit_pred = deephit.predict_surv_df(X_test.to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCHazard\n",
    "# Expected CPU runtime: 6m46s\n",
    "from pycox.models import PCHazard\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "\n",
    "batch_size = 4096*4\n",
    "epochs = 10000\n",
    "num_durations = 250\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "labtrans = PCHazard.label_transform(num_durations)\n",
    "y_train_tuple = labtrans.fit_transform(time_train.to_numpy().astype(np.float32), event_train.to_numpy().astype(np.float32))\n",
    "y_val_tuple = labtrans.fit_transform(time_val.to_numpy().astype(np.float32), event_val.to_numpy().astype(np.float32))\n",
    "val = X_val.to_numpy().astype(np.float32), y_val_tuple\n",
    "\n",
    "in_features = X_train.shape[1]\n",
    "num_nodes = [32, 32, 32]\n",
    "out_features = labtrans.out_features\n",
    "batch_norm = False\n",
    "dropout = 0.0\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout)\n",
    "pchazard = PCHazard(net, tt.optim.Adam, device=device)\n",
    "pchazard.optimizer.set_lr(0.0001)\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=200)]\n",
    "verbose = False\n",
    "log = pchazard.fit(X_train.to_numpy().astype(np.float32), y_train_tuple, batch_size, epochs, callbacks, verbose, val_data=val, val_batch_size=batch_size)\n",
    "pchazard_pred = pchazard.predict_surv_df(X_test.to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCSurvival\n",
    "# Expected CPU runtime: ??\n",
    "import sys\n",
    "import torch\n",
    "from dcsurvival.dirac_phi import DiracPhi\n",
    "from dcsurvival.survival import SurvivalCopula_sumofull\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "torch.set_num_threads(24)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_previous = True\n",
    "depth = 2\n",
    "widths = [100, 100]\n",
    "lc_w_range = (0, 1.0)\n",
    "shift_w_range = (0., 2.0)\n",
    "num_epochs = 100000\n",
    "batch_size = 4096*4\n",
    "early_stop_epochs = 500\n",
    "\n",
    "times_tensor_train = torch.tensor(time_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "event_indicator_tensor_train = torch.tensor(event_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "covariate_tensor_train = torch.tensor(X_train.to_numpy(), dtype=torch.float64).to(device)\n",
    "\n",
    "times_tensor_val = torch.tensor(time_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "event_indicator_tensor_val = torch.tensor(event_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "covariate_tensor_val = torch.tensor(X_val.to_numpy(), dtype=torch.float64).to(device)\n",
    "\n",
    "dataset = TensorDataset(covariate_tensor_train, times_tensor_train, event_indicator_tensor_train)\n",
    "val_dataset = TensorDataset(covariate_tensor_val, times_tensor_val, event_indicator_tensor_val)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "phi = DiracPhi(depth, widths, lc_w_range, shift_w_range, device, tol = 1e-14).to(device)\n",
    "dcs_model = SurvivalCopula_sumofull(phi, device = device, num_features=X_train.shape[1], \n",
    "                                tol=1e-14, hidden_size = 32)\n",
    "dcs_model.to(device)\n",
    "\n",
    "if load_previous == True:\n",
    "    checkpoint = torch.load(\"/home/SurvivalACNet_sumo/checkpoints/weight.pth\")\n",
    "    dcs_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = optim.AdamW([{\"params\": dcs_model.sumo_e.parameters(), \"lr\": 1e-6},\n",
    "                        {\"params\": dcs_model.sumo_c.parameters(), \"lr\": 1e-6},\n",
    "                        {\"params\": dcs_model.phi.parameters(), \"lr\": 1e-6}\n",
    "                    ])\n",
    "# Train the model\n",
    "best_val_loglikelihood = float(\"-inf\")\n",
    "epochs_no_improve = 0 \n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "# for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    logloss = dcs_model(covariate_tensor_train, times_tensor_train, event_indicator_tensor_train, max_iter = 10000)\n",
    "    (-logloss).backward()\n",
    "    optimizer.step()\n",
    "    # for covariates, times, events in dataloader:  # iterate over batches \n",
    "    #     optimizer.zero_grad()\n",
    "    #     logloss = dcs_model(covariates, times, events, max_iter = 10000)\n",
    "    #     (-logloss).backward() \n",
    "    #     optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        val_loglikelihood = dcs_model(covariate_tensor_val, times_tensor_val, event_indicator_tensor_val, max_iter = 10000)\n",
    "        print(\"epoch\", epoch, \"train likelihood\", logloss.item(),\"val likelihood\", val_loglikelihood.item())\n",
    "        if val_loglikelihood > (best_val_loglikelihood ):\n",
    "            best_val_loglikelihood = val_loglikelihood\n",
    "            epochs_no_improve = 0\n",
    "            torch.save({\"epoch\": epoch, \"model_state_dict\": dcs_model.state_dict(),\"loss\": best_val_loglikelihood,\n",
    "                        }, \"/home/SurvivalACNet_sumo/checkpoints/weight.pth\")\n",
    "        else:\n",
    "            epochs_no_improve = epochs_no_improve + 100\n",
    "    # Early stopping condition\n",
    "    if epochs_no_improve == early_stop_epochs:\n",
    "        # print(\"Early stopping triggered at epoch: %s\" % epoch)\n",
    "        break\n",
    "# load the best model\n",
    "checkpoint = torch.load(\"/home/SurvivalACNet_sumo/checkpoints/weight.pth\")\n",
    "dcs_model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setp = 5\n",
    "\n",
    "print(X_test.shape)\n",
    "times = np.arange(time_test.min(), time_test.max(), step)\n",
    "\n",
    "# times_tensor = torch.tensor(times).to(device)\n",
    "# covariate_tensor_test = torch.tensor(X_test.to_numpy(), dtype=torch.float64).to(device)\n",
    "# survprob_matrix_list = []\n",
    "# for time in times_tensor:\n",
    "#     temp = 1- dcs_model.survival(time, covariate_tensor_test).cpu().detach().numpy()\n",
    "#     survprob_matrix_list.append(temp)\n",
    "# survprob_matrix = np.vstack(survprob_matrix_list)\n",
    "# survprob_dcsurvival = list(survprob_matrix.transpose())\n",
    "\n",
    "survprob_rsf = [1-rsf_func[i](times) for i in range(X_test.shape[0])]\n",
    "survprob_coxph = [1-coxph_func[i](times) for i in range(X_test.shape[0])]\n",
    "\n",
    "survprob_deepsurv = [[1-deepsurv_pred[i][time] for time in deepsurv_pred.index] for i in range(X_test.shape[0])]\n",
    "survprob_pchazard = [[1-pchazard_pred[i][time] for time in pchazard_pred.index] for i in range(X_test.shape[0])]\n",
    "survprob_deephit = [[1-deephit_pred[i][time] for time in deephit_pred.index] for i in range(X_test.shape[0])]\n",
    "survprob_coxcc = [[1-coxcc_pred[i][time] for time in coxcc_pred.index] for i in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_l is the event time\n",
    "y_l = []\n",
    "prob_rsf = []\n",
    "prob_coxph=[]\n",
    "prob_deepsurv = []\n",
    "prob_deephit = []\n",
    "prob_pchazard = []\n",
    "prob_coxcc = []\n",
    "# prob_dcsurvival = []\n",
    "\n",
    "for j in range(len(survprob_coxph)): #\n",
    "    k = 0\n",
    "    for i in np.arange(time_test.min(),time_test.max(),step): # from min to max of test time, the number of steps\n",
    "        if k < len(survprob_coxph[0]):\n",
    "            # if i <= time_test[j]:\n",
    "            #     print(j)\n",
    "            #     y_l.append(0)\n",
    "            # else:\n",
    "            #     y_l.append(1)\n",
    "            prob_rsf.append(survprob_rsf[j][k])\n",
    "            prob_coxph.append(survprob_coxph[j][k])\n",
    "            k+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "for j in range(len(survprob_deepsurv)): #\n",
    "    k = 0\n",
    "    for i in np.arange(time_test.min(),time_test.max(),step): # from min to max of test time, the number of steps\n",
    "        if k < len(survprob_deepsurv[0]):\n",
    "            if i <= time_test[j]:\n",
    "                y_l.append(0)\n",
    "            else:\n",
    "                y_l.append(1)\n",
    "            prob_deepsurv.append(survprob_deepsurv[j][k])\n",
    "\n",
    "            prob_coxcc.append(survprob_coxcc[j][k])\n",
    "            prob_deephit.append(survprob_deephit[j][k])\n",
    "            prob_pchazard.append(survprob_pchazard[j][k])\n",
    "            # prob_dcsurvival.append(survprob_dcsurvival[j][k])\n",
    "            k+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "y_l = np.array(y_l)\n",
    "prob_rsf = np.array(prob_rsf)\n",
    "prob_coxph = np.array(prob_coxph)\n",
    "prob_deepsurv = np.array(prob_deepsurv)\n",
    "prob_deephit = np.array(prob_deephit)\n",
    "prob_pchazard = np.array(prob_pchazard)\n",
    "prob_coxcc = np.array(prob_coxcc)\n",
    "# prob_dcsurvival = np.array(prob_dcsurvival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8, 8))\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_coxph, ax = ax, name=\"CoxPH\", marker=\"s\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_rsf, ax = ax, name=\"RSF\", marker=\"o\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_deepsurv, ax = ax, name=\"DeepSurv\", marker=\"^\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_coxcc, ax = ax, name=\"CoxCC\", marker=\"H\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_deephit, ax = ax, name=\"DeepHit\", marker=\"p\")\n",
    "disp = CalibrationDisplay.from_predictions(y_l,prob_pchazard, ax = ax, name=\"PCHazard\", marker=\"*\")\n",
    "# disp = CalibrationDisplay.from_predictions(y_l,prob_dcsurvival, ax = ax, name=\"DCSurvival\", marker=\"D\")\n",
    "\n",
    "ax.set_xlabel(\"Mean Predicted Probability\", fontsize=14)\n",
    "ax.set_ylabel(\"Fraction of Positives\", fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
